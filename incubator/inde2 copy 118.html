1
9.3.2020.
Data and Web Science Group
Fakult√§t f√ºr Wirtschaftsinformatik und Wirtschaftsmathematik
Universit√§t Mannheim
CreativeCommons Attribution-NonCommercial-ShareAlike 4.0 International
4. Term Weighting and Vector Space Model
Prof. Dr. Goran Glava≈°
2
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
After this lecture, you‚Äôll...
ÔÇß Be familiar with your first ranked retrieval model (VSM)
ÔÇß Understand the TF-IDF term weighting scheme
ÔÇß Know how to rank documents according to cosine similarity
ÔÇß Know about some methods for speeding up VSM‚Äôs ranking
ÔÇß Be familiar with the multi-criteria ranking
3
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Outline
ÔÇß Recap of Lecture #3
ÔÇß Ranked retrieval and scoring
ÔÇß Vector space model
ÔÇß Term weighting (TF-IDF)
ÔÇß Ranking with cosine similarity
ÔÇß Speeding up VSM retrieval
ÔÇß Query parsing and multi-criteria ranking
4
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Recap of the previous lecture
ÔÇß Data structures for inverted index
ÔÇß Q: What are the different data structures we may use for indexing?
ÔÇß Q: How do we build index with a hash table (pros and cons)?
ÔÇß Q: How do we build index with a balanced tree (pros and cons)?
ÔÇß Tolerant retrieval: wild-card queries
ÔÇß Q: What are the different options for handling wild-card queries?
ÔÇß Q: What is a permuterm index and how do we use it for wild-card queries?
ÔÇß Q: How to use character indexes to support wild-card queries?
ÔÇß Tolerant retrieval: error correction
ÔÇß Q: How to correct the spelling by observing the terms in isolation?
ÔÇß Q: How do we use the edit distance to fix for misspellings?
ÔÇß Q: What are the different options for spelling correction in context?
5
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Recap of the previous lecture(s)
ÔÇß Inverted index is a data structure for computationally efficient retrieval
ÔÇß We‚Äôve examined different variants of the inverted index for different queries
ÔÇß Regular inverted index for simple Boolean queries
ÔÇß Positional index for phrase and proximity queries
ÔÇß Permuterm index for tolerant retrieval
ÔÇß Boolean retrieval has a major drawback
ÔÇß The results are not ranked
ÔÇß Without ranking: either too few or too many results
ÔÇß Document dj is represented by term vector [w1j, w2j, ..., wtj] where t is the number of
index terms
ÔÇß Let g be the function that computes the weights, i.e., wij = g(ki, dj)
ÔÇß Different choices for the weight-computation function g and the ranking function r define
different IR models
ÔÇß Today, we examine the first model for ranked retrieval ‚Äì vector space model (VSM)
ÔÇß We examine what g and r are for VSM
6
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Outline
ÔÇß Recap of Lecture #3
ÔÇß Ranked retrieval and scoring
ÔÇß Vector space model
ÔÇß Term weighting (TF-IDF)
ÔÇß Ranking with cosine similarity
ÔÇß Speeding up VSM retrieval
ÔÇß Query parsing and multi-criteria ranking
7
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Beyond Boolean retrieval
ÔÇß So far, all our queries were some variant of Boolean (simple, phrase, positional)
ÔÇß Document either match or not
ÔÇß Suitable for expert users with precise understanding of both
ÔÇß Their information needs
ÔÇß The document collection against which they spawn queries
ÔÇß Also suitable for applications: easily consume 1000s of results
ÔÇß Not suitable for most human users
ÔÇß Most users find it difficult (unnatural) to write Boolean queries
ÔÇß Most users cannot go through thousands of results the Boolean retrieval engine
returns on large collections (e.g., web)
8
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Beyond Boolean retrieval
ÔÇß Boolean queries often yield either too few (even 0) or too many (1000s) results
ÔÇß Q1: ‚Äûstandard user dlink 650‚Äù
ÔÇß 200K hits
ÔÇß Q2: ‚Äûstandard user dlink 650 no card found‚Äù
ÔÇß 0 hits
ÔÇß It takes a lot of skill, experience, and sometimes time to design a query that
produces a manageable number of hits
ÔÇß AND operator often drastically reduces the number of hits
ÔÇß OR operator often drastically increases the number of hits
ÔÇß Hard to find the balance
ÔÇß Solution: rank the documents and return the top N ranked hits
ÔÇß User directly chooses N, i.e., how many hits to process
9
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Ranked retrieval
ÔÇß IR models for ranked retrieval
ÔÇß Produce the ordering over the documents in the collection
ÔÇß Selection of top-ranked documents
ÔÇß May be done by the IR system
ÔÇß Cut the documents below rank N (i.e., top N)
ÔÇß Cut documents below some treshold score value
ÔÇß May be left to the user
ÔÇß Entire ranking is returned (e.g., with paging)
ÔÇß Free text search
ÔÇß No query language with operators and expressions
ÔÇß Query is simply one or more words in natural language
ÔÇß Two separate design-decisions, but often go together
ÔÇß Free text search & ranked retrieval
10
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Ranked retrieval
ÔÇß Assumption: The ranking of the documents is based on the relevance
ÔÇß The ranking/scoring function (r) captures the extent of relevance of the document
for the query
ÔÇß All IR models that we will cover from now onwards are ranked retrieval models
ÔÇß They differ in the scoring function r they use
ÔÇß Common-sense assumptions
ÔÇß Let‚Äôs start from a single-term query qt
ÔÇß If the term does not occur in the document d ‚Äì r(qt, d) = 0
ÔÇß The more frequent the query term in the document, the higher the score should be
ÔÇß r(q, d) ‚àù ft,d
11
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Ranked retrieval: naive approach
ÔÇß First idea: use Jaccard coefficient ‚Äì a measure of overlap of two sets A and B:
Jaccard(A, B) = |A ‚à© B| / |A ‚à™ B|
Jaccard(A, A) = 1
Jaccard(A, B) = 0 iff A ‚à© B = √ò
ÔÇß The Jaccard index is always between 0 and 1
ÔÇß Sets A and B don‚Äôt have to be of the same size
ÔÇß Shortcomings of using Jaccard coefficient as a scoring function
1. Term frequency in each of the documents is not taken into account
2. The overall frequency of the term in the collection (or language in general) is not
accounted for ‚Äì rare terms are more informative
3. There are more sophisticated ways to normalize for the document length
12
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Outline
ÔÇß Recap of Lecture #3
ÔÇß Ranked retrieval and scoring
ÔÇß Vector space model
ÔÇß Term weighting (TF-IDF)
ÔÇß Ranking with cosine similarity
ÔÇß Speeding up VSM retrieval
ÔÇß Query parsing and multi-criteria ranking
13
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Term frequency
ÔÇß Term frequency tf(t,d) is a measure that denotes how frequently the term t
appears in the document d
ÔÇß Q: Shall we use the raw frequency (i.e., raw number of occurrences of t in d) as a
measure of term frequency?
ÔÇß A document d1 with 10 occurrences of a query term t is probably more relevant than
a document d2 with 1 occurrence. But is it 10 times more relevant?
ÔÇß A document d1 contains 100.000 tokens and 4 occurrences of term t whereas the
document d2 contains 500 tokens and 3 occurrences of term t. Which document is
more relevant?
ÔÇß Relevance does not increase linearly with term frequency
ÔÇß Raw term frequency does not account for document length
14
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Term frequency
ÔÇß Let‚Äôs fix for the previous two observations
1. Relevance does not increase linearly with term frequency
ÔÇß Let‚Äôs take the logarithm of the raw frequency
tf(t,d) = 1 + log10(ft,d), if ft,d > 0, otherwise 0
2. Raw term frequency does not account for document length
ÔÇß Let‚Äôs normalize with the frequency of the most frequent term in the document
tf(t,d) = ft,d / max{ft‚Äô,d : t‚Äô ‚àà d}
ÔÇß Combining the two:
tf(t,d) = (1 + log10(ft,d)) / (1 + log10 (max{ft‚Äô,d : t‚Äô ‚àà d}))
ÔÇß if ft,d > 0, otherwise 0
15
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Global frequency
ÔÇß Assumption: rare terms are more informative/important than frequent terms
ÔÇß Consider the query ‚Äûarachnocentric shop‚Äù
ÔÇß A document containing rare term ‚Äûarachnocentric‚Äù is more likely to be relevant than
the document containing the more frequent term ‚Äûshop‚Äù
ÔÇß We want a higher weight for rare terms like ‚Äûarachnocentric‚Äù
ÔÇß We will use document frequency, i.e., the number of documents in the collection
to account for global rarity/frequency of the terms
16
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Inverse document frequency
ÔÇß Assumption: the informativeness of the term t is inversely proportional to the
number of documents in the collection in which the term appears
ÔÇß The less documents in which the term appears ‚Äì the bigger weight
ÔÇß Inverse document frequency (on the document collection D)
idf(t) = log10(|D| / |{d‚Äô ‚àà D : t ‚àà d‚Äô}|)
ÔÇß The logarithm is used to ‚Äûdampen‚Äù the effect for terms that appear in very few
documents
ÔÇß E.g., only in one or two documents
ÔÇß The base of the logarithm is not particularly important
17
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Inverse document frequency ‚Äì example
ÔÇß Term frequency (TF) value of the term is computed for every document
ÔÇß N documents (d1, d2, ..., dN) ÔÉ†N different TF scores for some term ti
ÔÇß tf(ti, d1), tf(ti, d2), ..., tf(ti, dN)
ÔÇß Inverse document frequency (IDF) is a single value for the term on the whole
document collection D (does not depend on particular document)
ÔÇß idf(ti) = idf(ti, D)
ÔÇß Example: N = 1 million documents
ÔÇß Q: What is the effect of idf for
single-term queries?
ÔÇß A: None. Q: Why?
term df(term) idf(term)
Frodo 10000 2
Sam 1000 3
stab 100 4
the 1000000 1
18
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Collection frequency vs. Document frequency
ÔÇß Collection frequency is the total number of occurrences of the term in the entire
collection, i.e., in all of the documents
ÔÇß I.e., counting multiple occurrences in documents
ÔÇß Using (inverse) collection frequency could be an alternative to (inverse)
document frequency
ÔÇß Q: Which is better?
ÔÇß Q: Should ‚ÄûFrodo‚Äù or ‚Äûblue‚Äù
get a higher weight?
Word Collection
frequency
Document
frequency
Frodo 100442 5135
blue 100350 20452
19
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
TF-IDF
ÔÇß Finally, the weight for the term ti within the document dj is computed by
multiplying the TF (local) and IDF (global) components:
wij = tf(ti, dj) * idf(ti)
tf(ti, dj) = (1 + log10(fti,dj)) / (1 + log10 (max{ft‚Äô,dj : t‚Äô ‚àà dj}))
idf(ti) = log10(|D| / |{d‚Äô ‚àà D : ti ‚àà d‚Äô}|)
ÔÇß TF-IDF is the best known weighting scheme in IR
ÔÇß TF-IDF score of term t within document d is larger
ÔÇß The larger the number of occurrences of t within d
ÔÇß The smaller the number of other documents d‚Äô in which t occurs
20
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Outline
ÔÇß Recap of Lecture #3
ÔÇß Ranked retrieval and scoring
ÔÇß Vector space model
ÔÇß Term weighting (TF-IDF)
ÔÇß Ranking with cosine similarity
ÔÇß Speeding up VSM retrieval
ÔÇß Query parsing and multi-criteria ranking
21
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Vector space model
ÔÇß Vector space model
ÔÇß Documents and queries considered to be bags of words
ÔÇß Both documents and queries are represented as vectors of TF-IDF weights of
vocabulary terms
ÔÇß TF-IDF score of vocabulary term not contained in the query/document is 0
ÔÇß Ranking function: similarity/distance between the two TF-IDF vectors (i.e., the
vector of the document and the vector of the query)
ÔÇß Q: What distance metric to use?
ÔÇß Euclidean distance?
ÔÇß Any other distance/similarity metric?
22
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Euclidean distance
ÔÇß Euclidean distance
ÔÇß Measures the distance between the ends (points) of the two vectors
ÔÇß The Euclidean distance between q and d2 is large
ÔÇß But the distribution of terms in the query q
and the distribution of terms in the document d2
are very similar.
ÔÇß E.g., q = [1, 2, 3, 4, 5],
d2 = [2, 4, 6, 8, 10]
23
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Euclidean distance ‚Äì shortcomings
ÔÇß Take a document d and append it N times to itself ‚Äì the obtained document is d‚Äô
ÔÇß Semantically, d and d‚Äô have the same content
ÔÇß If N is large (i.e., we appended d to itself many times) the Euclidean distance
between d and d‚Äô is going to be large
ÔÇß Yet, d and d‚Äô are semantically identical ‚Äì d‚Äô is as relevant for any query q as d is
ÔÇß However, the angle between vectors of d and d‚Äô is going to be zero
ÔÇß These two vectors have exactly the same direction
ÔÇß Angle between the vectors better captures the actual similarity
ÔÇß Key idea: rank documents according to the angle their vectors close with the
vector of the query
24
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Cosine similarity
ÔÇß The smaller the angle between two vectors is, the larger is the value of the cosine
of that angle
ÔÇß Cosine is a monotonically decreasing function on the [0¬∞, 180¬∞] interval
25
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Cosine similarity
ÔÇß Cosine similarity of two vectors is the cosine of the angle between them
ÔÇß Cosine similarity is not affected by the length of the input vectors (norms in the
denominator)
ÔÇß Cosine distance dC is simply computed as dC(x, y) = 1 ‚Äì cos(x, y)
26
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Normalization of vector length
ÔÇß Q: If the length is the issue for Euclidean distance, why don‚Äôt we simply compute the
Euclidean distance between unit-normalized vectors?
ÔÇß Q: What is the relation between Euclidean distance of unit-normalized vectors and
cosine distance?
ÔÇß A: Cosine distance between two vectors is quadratically proportional to the Euclidean
distance between unit-normalized versions of those vectors
ÔÇß A: The ranking produced by cosine distance is going to be the same as the ranking
produced by Euclidean distance between unit-normalized vectors
ÔÇß Cosine similarity between unit-normalized vectors amounts to their dot (scalar) product
27
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Normalized Euclidean vs. Cosine distance
28
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Ranking based on cosine similarity
29
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Vector space model ‚Äì example
ÔÇß Query: ‚ÄûFrodo stabs orc‚Äù
ÔÇß Document collection
ÔÇß D1: ‚ÄûFrodo accidentally stabbed Sam and then some orcs‚Äù
ÔÇß d2: ‚ÄûFrodo was stabbing regular orcs but never stabbed super orcs ‚Äì Uruk-Hais‚Äù
ÔÇß d3: ‚ÄûSam was having a barbecue with some friendly orcs‚Äù
1. For all documents, compute the TF-IDF score for each query term
idf(‚ÄûFrodo‚Äù) = log10(3/2) = 0.176; tf(‚ÄûFrodo‚Äù, d1) = 1, tf(‚ÄûFrodo‚Äù, d2) = 1, tf(‚ÄûFrodo‚Äù, d3) = 0
idf(‚Äûstab‚Äù) = log10(3/2) = 0.176; tf(‚Äûstab‚Äù, d1) = 1, tf(‚Äûstab‚Äù, d2) = 2, tf(‚Äûstab‚Äù, d3) = 0
idf(‚Äûorc‚Äù) = log10(3/3) = 0; tf(‚Äûorc‚Äù, d1) = 1, tf(‚Äûorc‚Äù, d2) = 2, tf(‚Äûorc‚Äù, d3) = 1
tf(‚ÄûFrodo‚Äù, q) = 1, tf(‚Äûstab‚Äù, q) = 1, tf(‚Äûorc‚Äù, q) = 1
2. Compute cosine similarities between vectors of q and each document
ÔÇß Q: Which term can we ignore for cosine similarity?
ÔÇß Q: Do we need to compute the norm of the query vector?
30
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Alternative weighting and normalization schemes
ÔÇß Most commonly implemented in IR systems:
ÔÇß TF: logarithmic, augmented, log average / log max ‚Äì equally common
ÔÇß IDF: logarithmic
ÔÇß Normalization: L2 (Euclidian) norm (cosine similarity does it implicitly)
ÔÇß Sometimes, the weighting schemes for query and documents may differ
31
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Outline
ÔÇß Recap of Lecture #3
ÔÇß Ranked retrieval and scoring
ÔÇß Vector space model
ÔÇß Term weighting (TF-IDF)
ÔÇß Ranking with cosine similarity
ÔÇß Speeding up VSM retrieval
ÔÇß Query parsing and multi-criteria ranking
32
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Speeding up retrieval with VSM
ÔÇß Ranking all documents in the collection
ÔÇß Requires comparing the query TF-IDF vector with TF-IDF vectors of all documents
ÔÇß Infeasible for real-time querying on large collections
ÔÇß We need to reduce the cost of cosine (dot product) computations
1. By reducing the total number of cosines we compute
a) Prefiltering candidate documents for ranking (e.g., via Boolean retrieval)
b) By pre-clustering documents (based on their mutual similarity)
2. By reducing the set of query terms we consider (e.g., according to IDF scores)
ÔÇß Smaller set of candidate documents
ÔÇß Faster cosine computation (shorter vectors for dot product)
33
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Index-based elimination
ÔÇß Documents that do not contain any of the query terms will have the cosine
similarity of 0 with the query anyway
ÔÇß Idea: Fetch only the documents that contain at least one query term
ÔÇß Using the inverted index
ÔÇß For the free text query ‚Äût1 t2 ... tn‚Äù we spawn the Boolean query ‚Äût1 OR t2 OR ... OR tn‚Äù
ÔÇß Further possible speed-ups:
1. Fetch only documents that contain more than N query terms
2. Do not consider query terms with low IDF values
ÔÇß Q: Why?
ÔÇß A: Terms with low IDF scores appear in many (all?) documents in the collection, thus
matching such terms between query and documents does not affect the ranking much
ÔÇß A: Posting lists of terms with low IDF are long ‚Äì cosine computation for many docs
34
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Pre-clustering documents
ÔÇß If the document collection contains N documents, we randomly select N
documents, which we call leaders
ÔÇß For every other document in the collection
1. Compute the similarities (cosine of the angle between TF-IDF vectors) with all
leaders
2. Add the document to the cluster of the most similar leader
ÔÇß On average, a cluster will have N documents
ÔÇß Random sampling of clusters is desirable (reflects the document distribution)
ÔÇß Faster than any other strategy for selecting leaders
ÔÇß Leaders reflect the data distribution
ÔÇß Dense regions will have more leaders than sparse regions
35
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Pre-clustering documents
ÔÇß Retrieval with document pre-clustering is much faster
1. Measure the similarity of the query with cluster leaders
ÔÇß N cosine computations
2. Select the leader document dL which is most similar to the query
3. Compute the cosine similarities between the query vector and all documents in
the selected leader‚Äôs (dL) cluster
ÔÇß N cosine computations
4. (optional) if the users requires more results than there is documents in the cluster
of the most similar leader dL, proceed to the cluster of the next most similar leader
ÔÇß With pre-clustering, total of 2 N cosine computations ÔÉ† O( N)
ÔÇß Quadratically lower complexity than before (without preclustering ÔÉ† O(N))
ÔÇß Shortcoming: pre-clustering may lead to lower recall
ÔÇß Some relevant documents may not be in the cluster of the most similar leader
36
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Approximate cosine similarity
ÔÇß Idea: reduce the length of the vectors on which we compute cosine similarity
ÔÇß Only makes sense for queries with very many terms
ÔÇß If query has |V| terms, the cosine computation has complexity O(|V|)
ÔÇß Goal is to represent the query and document with a significantly shorter vector of
length M, M << V
ÔÇß Cosine computation on lower dimensional vectors is then faster, O(M)
ÔÇß Key question: how to select the lower-dimensional vector space in such a way
that relations between the original cosine similarities are preserved?
37
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Locality sensitive hashing
ÔÇß A vector space of lower dimensions that (perfectly or imperfectly) retains the
distances from the original space is called a low-dimensional embedding
ÔÇß Locality sensitive hashing (LSH)
ÔÇß A family of dimensionality reduction techniques that map the original vector space
into a lower-dimensional space
ÔÇß Maximizing the extent to which the new vector space retains the topology of the
original one
ÔÇß One simple LSH method we will examine closer:
ÔÇß Random projections
38
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Random projections
ÔÇß A locality sensitive hashing method based on similarities with random vectors
ÔÇß Hashing algorithm
1. Choose a set of M random vectors {r1, r2, ..., rM} in the original high-dimensional
vectors space (vector length |V|)
2. For each document TF-IDF vector d do
ÔÇß Compute the inner (dot) product of d and each random vector r: Œ∏(r, d) = ùëñ
|ùëâ| ùëüùëñ ‚àó ùëëùëñ
ÔÇß Hash each inner product: h(d, rk) = 1 if Œ∏(r, d) > t (treshold), else 0
3. Compute a new vector of hashes:
ÔÇß d‚Äô = [h(d, r1), h(d, r2), ..., h(d, rM)]
ÔÇß The number of selected random vectors, M, is the dimensionality of hashed vectors
ÔÇß Q: How does this hashing method preserve the relations between document
distances of the original space?
ÔÇß If d1 and d2 are more similar than d2 and d3 in original space, why is it likely that d‚Äô1
and d‚Äô2 will be more similar than d‚Äô2 and d‚Äô3 in the projected space?
39
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Champion lists
ÔÇß For each term ti store only the docs dj with highest scores wij
ÔÇß I.e., Store only the documents for which this term is relatively informative
ÔÇß Since idf(ti) is the same for all documents, we rank documents according to the TF
values, i.e., tf(ti, dj)
ÔÇß Put differently, if the term is relatively rare in the document, we treat it like it didn‚Äôt
appear in the document at all
ÔÇß Don‚Äôt keep that document index in the term posting
ÔÇß Such reduced term posting lists are called champion lists (also fancy lists)
ÔÇß The documents in the champion list can be decided in two different ways
1. Taking the top N documents with highest tf(ti, dj) scores
ÔÇß Posting lists of terms of same length N (unless the original posting was shorter)
2. Taking all documents for which the tf(ti, dj) is above some treshold value
ÔÇß Different lengths of postings for different terms
40
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Champion lists
ÔÇß Building the champion lists during indexing
ÔÇß Independent of any query that will be posed
ÔÇß When query is posed, it is possible that users wants more ranked results than what is
the length of the champion list for some term
ÔÇß If champion lists are the only postings we kept, we cannot provide more results
ÔÇß Solution: two-layer indexing
ÔÇß Champion lists and regular (full) posting lists
1. We try to answer the query using only the champion lists first
2. If the number of hits using champion lists is smaller than the number of results
user is looking for, return the hits using full posting lists
41
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Tiered index
ÔÇß Generalization of the two layer index
ÔÇß We can have posting lists of more than two layers (several segments)
ÔÇß Tiered index is the index in which the postings are broken down hierarchically
into several lists
ÔÇß Tiers of decreasing importance
ÔÇß For term ti, break-down of documents is usually done according to the tf(ti, d) scores
ÔÇß In each tier, however, the documents are sorted according to docID, not tf(ti, d)
ÔÇß We still need to perform posting merges in linear time
ÔÇß Look-up in tiered index
ÔÇß We first look into the the top tier, i.e., merge the term postings of the first tier
ÔÇß If the merges over the top-tier postings result in too few hits, we continue to merge
lists of the lower tiers
42
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Tiered index ‚Äì example
ÔÇß ‚ÄûFrodo‚Äù -> T1: [2, 19, 24, 126]
-> T2: [1, 3, 12, 27, 69, 111]
-> T3: [7, 20, 76]
ÔÇß ‚ÄûSam‚Äù -> T1: [2, 18, 24, 158]
-> T2: [1, 6, 69, 126]
-> T3: [44, 90]
ÔÇß Query: ‚ÄûFrodo and Sam‚Äù, we need to return at least 3 results!
ÔÇß Merge at T1: [2, 24] ÔÉ† only 2 results, we need to go to T2 as well
ÔÇß Second iteration
ÔÇß Q: merge(‚ÄûFrodo‚Äù, ‚ÄûSam‚Äù, T1) ‚à™ merge(‚ÄûFrodo‚Äù, ‚ÄûSam‚Äù, T2)?
ÔÇß A: No, we have to do ‚Äì merge(sort(‚ÄûFrodo‚Äù, T1, T2), sort(‚ÄûSam‚Äù, T1, T2))
ÔÇß Final result: [1, 2, 24, 69, 126]
43
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Outline
ÔÇß Recap of Lecture #3
ÔÇß Ranked retrieval and scoring
ÔÇß Vector space model
ÔÇß Term weighting (TF-IDF)
ÔÇß Ranking with cosine similarity
ÔÇß Speeding up VSM retrieval
ÔÇß Query parsing and multi-criteria ranking
44
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Phrase queries and scoring function
ÔÇß Remember the phrase queries from Lecture 2?
ÔÇß E.g., ‚ÄûFrodo Baggins‚Äù, ‚ÄûLas Angeles‚Äù, ‚Äûhot potato‚Äù
ÔÇß We handled the phrase queries with the positional index
ÔÇß The vanilla vector space model uses the regular index
ÔÇß No positional information, bag-of-words document representation
ÔÇß How can we account for phrase queries with VSM ranking?
1. If proximity is a hard requirement from the users
ÔÇß Build the positional index and combine it with VSM ranking
2. If the proximity is a soft requirement (i.e., documents where query terms are
closer together are preferred)
ÔÇß Incorporate a ‚Äûmeasure of query term proximity‚Äù into a ranking function for documents
ÔÇß We still need the positional index ÔÅå. Q: Why?
45
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Query parsing and multiple query spawning
ÔÇß IR systems often have query parsing components to analyse the queries
ÔÇß Based on the results of the analysis, the initial query can be ‚Äûrewritten‚Äù
ÔÇß Some terms might be ommitted
ÔÇß Your original query might not be the actual query to be matched against
document collection
ÔÇß Your original query may be replaced with several queries
ÔÇß E.g., ‚Äûrising interest rates‚Äù ÔÉ† ‚Äûrising interest‚Äù and ‚Äûinterest rates‚Äù
ÔÇß Example sequence of queries by query parser:
1. Run the query as a phrase query ‚Äûrising interest rates‚Äù
ÔÇß If enough hits, proceed to ranking
2. If not enough hits in 1., spawn ‚Äûrising interest‚Äù and ‚Äûinterest rates‚Äù
ÔÇß If enough hits, proceed to ranking of all documents fetched in 1. and 2.
3. If still not enough hits, spawn ‚Äûrising‚Äù, ‚Äûinterest‚Äù, and ‚Äûrates‚Äù
ÔÇß Rank all retrieved documents in 1., 2., and 3. with VSM
46
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Document quality
ÔÇß Intuitive assumptions:
ÔÇß Documents have intrinsic quality which is independent of a particular query
ÔÇß E.g., more reliable (e.g., Wikipedia) vs. less reliable sources (spam sites)
ÔÇß In case when two documents have similar relevance for the query, we would like to
rank one with higher quality above the one with lower quality
ÔÇß Static document quality
ÔÇß Intrinsic property of the document itself, does not depend on other documents
ÔÇß E.g., digitally born documents have higher quality than OCR-ed ones
ÔÇß E.g., on the Web, we might consider Wikipedia pages to be of high quality
ÔÇß Dynamic document quality
ÔÇß Depends on the associations with other documents
ÔÇß Link analysis based quality: crucial in web search (more in Lecture 11 ÔÅä)
47
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Aggregating different scores
ÔÇß What if our ranking function needs to take into account several scores? For
example:
ÔÇß Cosine similarity of TF-IDF vectors
ÔÇß Proximity of query terms in documents
ÔÇß Static quality of documents
ÔÇß Relevant questions:
ÔÇß What is the relative importance of different scores?
ÔÇß Are different scores even on the same scale (order of magnitude)?
ÔÇß Methods
ÔÇß Expert designed aggregate function
ÔÇß Learning to rank: aggregate function learned with machine-learning algorithms
ÔÇß More in Lecture 9 ÔÅä
48
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
Putting it all together
ÔÇß Free text queries vs. Boolean queries (ranked retrieval vs. Boolean retrieval)
ÔÇß Query: ‚ÄûFrodo and Sam saw orcs‚Äù
ÔÇß Boolean: document relevant only if contains ‚ÄûFrodo‚Äù and ‚ÄûSam‚Äù and ‚Äûsee‚Äù and ‚Äûorc‚Äù
ÔÇß Ranked: document may be relevant if it, e.g., contains only ‚ÄûFrodo‚Äù and ‚Äûorc‚Äù
ÔÇß But the indexing mechanisms we introduced with Boolean retrieval are employed
for ranked retrieval as well
ÔÇß Computing ranking scores for all documents is expensive
ÔÇß Using inverted index to obtain a smaller subset of documents, which are then ranked
ÔÇß But not too small ‚Äì recall the tiered index
ÔÇß We may have several different ranking criteria
ÔÇß We need to learn how to combine them into a single relevance score
49
9.3.2020.IR & WS, Lecture 4: Term Weighting and Vector Space Model
After this lecture, you are...
ÔÇß Are familiar with your first ranked retrieval model (VSM)
ÔÇß Understand the TF-IDF term weighting scheme
ÔÇß Know how to rank documents according to cosine similarity
ÔÇß Know about some methods for speeding up VSM‚Äôs ranking
ÔÇß Are familiar with multi-criteria ranking